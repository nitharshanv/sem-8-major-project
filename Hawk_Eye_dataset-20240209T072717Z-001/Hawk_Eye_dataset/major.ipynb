{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqLVHy7XJVjg"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Python312\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras import layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyIwLQVlLc46",
        "outputId": "5080164e-c020-4567-bb3b-3123e5743147"
      },
      "outputs": [],
      "source": [
        "directory=r\"D:\\Hawk_Eye_dataset-20240209T072717Z-001\\Hawk_Eye_dataset\\Train\"\n",
        "\n",
        "image_size = (180, 180)\n",
        "batch_size = 128\n",
        "train_ds= keras.utils.image_dataset_from_directory(directory,validation_split=None,subset=None,seed=1337,image_size=image_size,batch_size=batch_size,shuffle=True)\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13r3KJelbkvB"
      },
      "outputs": [],
      "source": [
        "data_augmentation_layers = [    layers.RandomFlip(\"horizontal\"),    layers.RandomRotation(0.1)]\n",
        "def data_augmentation(images):\n",
        "  for layer in data_augmentation_layers:\n",
        "    images=layer(images)\n",
        "  return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95pFMyVOdoaw"
      },
      "outputs": [],
      "source": [
        "train_ds=train_ds.map( lambda img, label: (data_augmentation(img), label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmcjTw7efhOW",
        "outputId": "0c20be3a-66dc-453e-8b27-5fd942e83183"
      },
      "outputs": [],
      "source": [
        "print(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CZUYvB4QgnHt",
        "outputId": "a1812578-d9d3-47d0-8f8c-51440c34c6a9"
      },
      "outputs": [],
      "source": [
        "def make_model(input_shape, num_classes):\n",
        "  inputs = keras.Input(shape=input_shape)\n",
        "  # Entry block\n",
        "  x = layers.Rescaling(1.0 / 255)(inputs)\n",
        "  x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "  previous_block_activation = x # Set aside residual\n",
        "  for size in [256, 512, 728]:\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "    # Project residual\n",
        "    residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(previous_block_activation)\n",
        "    x = layers.add([x, residual]) # Add back residual\n",
        "    previous_block_activation = x # Set aside next residual\n",
        "  x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "  x = layers.GlobalAveragePooling2D()(x)\n",
        "  if num_classes == 10:\n",
        "    units = 1\n",
        "  else:\n",
        "    units = num_classes\n",
        "  x = layers.Dropout(0.25)(x)\n",
        "  # We specify activation=None so as to return logits\n",
        "  outputs = layers.Dense(units, activation=None)(x)\n",
        "  return keras.Model(inputs, outputs)\n",
        "model = make_model(input_shape=image_size + (3,), num_classes=10)\n",
        "keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TqQiIWPc7cn"
      },
      "source": [
        "validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWDucE_gc9S4",
        "outputId": "ff680b12-8c43-4f6e-9cee-7a9bddcafac6"
      },
      "outputs": [],
      "source": [
        "val_directory=\"/content/drive/MyDrive/Hawk_Eye_dataset/validation\"\n",
        "\n",
        "image_size = (180, 180)\n",
        "batch_size = 128\n",
        "test_ds= keras.utils.image_dataset_from_directory(directory,validation_split=None,subset=None,seed=1337,image_size=image_size,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZcXAf6Jdhzm"
      },
      "outputs": [],
      "source": [
        "test_ds=test_ds.map( lambda img, label: (data_augmentation(img), label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "62Q1LDvXdSoe",
        "outputId": "f8f75b9e-0b5c-4e51-b093-6f43bfd3b602"
      },
      "outputs": [],
      "source": [
        "epochs = 25\n",
        "callbacks =None\n",
        "model.compile(optimizer=keras.optimizers.Adam(3e-4),loss=keras.losses.BinaryCrossentropy(from_logits=True),metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")])\n",
        "model.fit(train_ds,epochs=epochs,callbacks=callbacks,validation_data=None)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
